# -*- coding: utf-8 -*-
"""Untitled24.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lLm2938x39XYXMyQf0z_j7iQBgmtlB9Q
"""

# !pip install scikit-plot==0.3.7

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd, numpy as np
import matplotlib.pyplot as plt

df = pd.read_csv('./dataset/results_r_copy.csv')
df.tail(2)

# df['AC'].isnull().values.any()

X = df.drop(['Season','DateTime','home_team_name','away_team_name',
             'FTR','FTHG','FTAG','HTHG','HTAG','HTR'], axis = 1)
y= df['FTR']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8,random_state=27)
# y_train
# X_test



from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier(criterion='gini', splitter='best', 
                       max_depth=None, min_samples_split=2, min_samples_leaf=1,
                       min_weight_fraction_leaf=0.0, max_features=None, random_state=35,
                       max_leaf_nodes=None,
                       min_impurity_decrease=0.0, class_weight=None, ccp_alpha=0.0)
dt.fit(X_train,y_train)

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(n_estimators=100,criterion='gini',
                            max_depth=None, min_samples_split=2, min_samples_leaf=1, 
                            min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None,
                            min_impurity_decrease=0.0, bootstrap=True, oob_score=False,
                            n_jobs=None, random_state=35, verbose=0, warm_start=False,
                            class_weight=None, ccp_alpha=0.0, max_samples=None) 
rf.fit(X_train,y_train)

from sklearn.ensemble import GradientBoostingClassifier

xgB =  GradientBoostingClassifier( loss='deviance', learning_rate=0.01, n_estimators=100, 
                                    subsample=1.0, criterion='friedman_mse', 
                                    min_samples_split=2, min_samples_leaf=1,
                                    min_weight_fraction_leaf=0.0,
                                    max_depth=5, min_impurity_decrease=0.0, init=None,
                                    random_state=35,
                                    max_features=7, verbose=0,
                                    max_leaf_nodes=None, warm_start=False, validation_fraction=0.1,
                                    n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)
xgB.fit(X_train,y_train)

from sklearn.ensemble import AdaBoostClassifier

ada =  AdaBoostClassifier(n_estimators=50,
                   learning_rate=0.1, algorithm='SAMME.R', 
                   random_state=35)
ada.fit(X_train,y_train)


import pickle
with open('jan22_model','wb') as f:
    pickle.dump(xgB, f)
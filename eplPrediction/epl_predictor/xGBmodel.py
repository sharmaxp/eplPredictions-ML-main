# -*- coding: utf-8 -*-
"""Untitled23.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1awJ1LSvHZM0uK5gvEDgGl_pbBddJecpn
"""

import pandas as pd, numpy as np

df = pd.read_csv('./dataset/results_r_copy.csv')
# df.tail(2)

X = df.drop(['Season','DateTime','home_team_name','away_team_name','FTR','FTHG','FTAG','HTHG','HTAG','HTR'], axis = 1)
# X
y= df['FTR']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.85)
X_train.shape, X_test.shape
# y_train
# X_test.head(1)
# a

from sklearn.ensemble import GradientBoostingClassifier

xgB =  GradientBoostingClassifier( loss='deviance', learning_rate=0.1, n_estimators=100, 
                                    subsample=1.0, criterion='friedman_mse', 
                                    min_samples_split=2, min_samples_leaf=1,
                                    min_weight_fraction_leaf=0.0,
                                    max_depth=3, min_impurity_decrease=0.0, init=None,
                                    random_state=None,
                                    max_features=None, verbose=0,
                                    max_leaf_nodes=None, warm_start=False, validation_fraction=0.1,
                                    n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)
xgB.fit(X_train,y_train)
print(xgB.score(X_train,y_train))

def xGBmodel(X_train,y_train):
  from sklearn.model_selection import GridSearchCV
  xgBoost_algo = GradientBoostingClassifier()
  xgBoost_algo_params = {
        'learning_rate' : [0.04],
        'n_estimators' : [100],
        'max_depth': [3,4,5,7],
        'min_samples_split' : [2,4,5],
        'min_samples_leaf' : [5,6],
        'max_features' : [5,7,8],
    }
  grid_search_xgBoost = GridSearchCV(estimator=xgBoost_algo,
                            param_grid=xgBoost_algo_params,
                            cv = 4,
                            n_jobs=-1, verbose=1, scoring="accuracy")
  grid_search_xgBoost.fit(X_train, y_train)
  print(grid_search_xgBoost.score(X_train, y_train))

  return grid_search_xgBoost

model = xGBmodel(X_train,y_train)

# model.predict(X_test)

# model.best_params_

import pickle
with open('xGBmodel','wb') as f:
    pickle.dump(model, f)